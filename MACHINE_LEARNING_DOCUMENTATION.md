# ü§ñ Documentaci√≥n de Machine Learning - SIAC

## Algoritmos Implementados

Este documento describe los 3 algoritmos de Machine Learning aplicados al an√°lisis de encuestas de conductores en el sistema SIAC.

---

## 1. K-Means Clustering üéØ

### Descripci√≥n
K-Means es un algoritmo de **aprendizaje no supervisado** que agrupa datos en K clusters bas√°ndose en similitudes. Agrupa conductores con patrones de comportamiento similares.

### Implementaci√≥n
```php
public function kMeansClustering($surveys, $k = 3, $maxIterations = 100)
```

### Par√°metros
- **$surveys**: Colecci√≥n de encuestas
- **$k**: N√∫mero de clusters (por defecto 3)
- **$maxIterations**: M√°ximo de iteraciones (por defecto 100)

### Caracter√≠sticas Utilizadas
1. **Velocidad promedio** (avg_speed)
2. **N√∫mero de incidentes** (incidents_count)
3. **Nivel de estr√©s** (stress_level)
4. **Satisfacci√≥n** (satisfaction_score)
5. **Experiencia de conducci√≥n** (driving_experience)

### Proceso
1. **Normalizaci√≥n**: Escala todas las caracter√≠sticas a rango [0, 1]
2. **Inicializaci√≥n**: Selecciona K puntos aleatorios como centroides iniciales
3. **Asignaci√≥n**: Cada conductor se asigna al centroide m√°s cercano (distancia euclidiana)
4. **Actualizaci√≥n**: Recalcula centroides como promedio de puntos asignados
5. **Convergencia**: Repite hasta que centroides no cambien significativamente

### Interpretaci√≥n de Clusters
- **Cluster 1 - Conductor Seguro**: Velocidad < 85 km/h, Incidentes < 5, Estr√©s < 5
- **Cluster 2 - Conductor Moderado**: Valores intermedios
- **Cluster 3 - Conductor de Alto Riesgo**: Velocidad > 100 km/h O Incidentes > 8 O Estr√©s > 7

### Salida
```json
{
  "clusters": {"user_id_1": 0, "user_id_2": 1, ...},
  "centroids": [centroid1, centroid2, centroid3],
  "interpretation": {
    "0": {
      "label": "Conductor Seguro",
      "count": 15,
      "avgSpeed": 72.3,
      "avgIncidents": 3.2,
      "avgStress": 4.1,
      "avgSatisfaction": 8.5
    }
  },
  "iterations": 12
}
```

### F√≥rmula de Distancia Euclidiana
```
d(p, q) = ‚àö(Œ£(p_i - q_i)¬≤)
```

Donde:
- p, q = dos puntos de datos
- i = cada caracter√≠stica (speed, incidents, stress, satisfaction, experience)

---

## 2. K-Nearest Neighbors (k-NN) üìç

### Descripci√≥n
k-NN es un algoritmo de **aprendizaje supervisado** que predice el nivel de riesgo de un conductor bas√°ndose en los K conductores m√°s similares (vecinos m√°s cercanos).

### Implementaci√≥n
```php
public function kNearestNeighbors($surveys, $newDriver, $k = 5)
```

### Par√°metros
- **$surveys**: Datos de entrenamiento (encuestas existentes)
- **$newDriver**: Nuevo conductor a clasificar
  ```php
  [
    'speed' => 95,
    'incidents' => 6,
    'stress' => 6,
    'experience' => 5
  ]
  ```
- **$k**: N√∫mero de vecinos a considerar (por defecto 5)

### Caracter√≠sticas Utilizadas
1. Velocidad promedio
2. N√∫mero de incidentes
3. Nivel de estr√©s
4. A√±os de experiencia

### Proceso
1. **Normalizaci√≥n**: Escala caracter√≠sticas a [0, 1]
2. **C√°lculo de Distancias**: Calcula distancia euclidiana del nuevo conductor a todos los existentes
3. **Selecci√≥n de Vecinos**: Ordena por distancia y toma los K m√°s cercanos
4. **Votaci√≥n**: Cuenta las etiquetas de riesgo de los K vecinos
5. **Predicci√≥n**: La clase con m√°s votos es la predicci√≥n final

### Etiquetas de Riesgo
```php
private function getRiskLabel($survey)
{
    if ($survey->avg_speed > 100 || $survey->incidents_count > 8 || $survey->stress_level > 7) {
        return 'Alto Riesgo';
    } elseif ($survey->avg_speed < 85 && $survey->incidents_count < 5 && $survey->stress_level < 5) {
        return 'Bajo Riesgo';
    }
    return 'Riesgo Moderado';
}
```

### Salida
```json
{
  "prediction": "Riesgo Moderado",
  "confidence": 60.0,
  "neighbors": [
    {"index": 12, "distance": 0.23, "label": "Riesgo Moderado"},
    {"index": 45, "distance": 0.31, "label": "Riesgo Moderado"},
    {"index": 8, "distance": 0.35, "label": "Alto Riesgo"},
    {"index": 23, "distance": 0.41, "label": "Riesgo Moderado"},
    {"index": 17, "distance": 0.44, "label": "Bajo Riesgo"}
  ],
  "votes": {
    "Riesgo Moderado": 3,
    "Alto Riesgo": 1,
    "Bajo Riesgo": 1
  }
}
```

### C√°lculo de Confianza
```
Confianza = (Votos de clase ganadora / K) √ó 100
```

Ejemplo: 3 votos de 5 = 60% de confianza

---

## 3. Feature Importance (Importancia de Caracter√≠sticas) üìä

### Descripci√≥n
Analiza qu√© caracter√≠sticas tienen mayor impacto en la satisfacci√≥n del usuario utilizando el **Coeficiente de Correlaci√≥n de Pearson**.

### Implementaci√≥n
```php
public function featureImportance($surveys)
```

### Caracter√≠sticas Analizadas
1. Velocidad Promedio
2. N√∫mero de Incidentes
3. Nivel de Estr√©s
4. A√±os de Experiencia
5. Distancia Diaria
6. Frecuencia de Alertas

### Coeficiente de Pearson
Mide la correlaci√≥n lineal entre dos variables en el rango [-1, 1]:

```
r = Œ£((x_i - xÃÑ)(y_i - »≥)) / ‚àö(Œ£(x_i - xÃÑ)¬≤ √ó Œ£(y_i - »≥)¬≤)
```

Donde:
- x = valores de la caracter√≠stica
- y = valores de satisfacci√≥n
- xÃÑ, »≥ = promedios

### Interpretaci√≥n
- **r = 1**: Correlaci√≥n positiva perfecta (cuando X aumenta, Y aumenta proporcionalmente)
- **r = -1**: Correlaci√≥n negativa perfecta (cuando X aumenta, Y disminuye proporcionalmente)
- **r = 0**: Sin correlaci√≥n
- **|r| > 0.7**: Correlaci√≥n fuerte
- **|r| > 0.4**: Correlaci√≥n moderada
- **|r| < 0.4**: Correlaci√≥n d√©bil

### Importancia
```
Importancia (%) = |r| √ó 100
```

### Salida
```json
{
  "Nivel de Estr√©s": {
    "correlation": -0.8234,
    "importance": 82.34
  },
  "Incidentes": {
    "correlation": -0.6521,
    "importance": 65.21
  },
  "Velocidad Promedio": {
    "correlation": -0.5123,
    "importance": 51.23
  },
  "Experiencia": {
    "correlation": 0.3456,
    "importance": 34.56
  }
}
```

**Interpretaci√≥n del ejemplo:**
- **Nivel de Estr√©s**: Correlaci√≥n negativa fuerte (-0.82). Cuando el estr√©s aumenta, la satisfacci√≥n disminuye significativamente.
- **Incidentes**: Correlaci√≥n negativa moderada. M√°s incidentes reducen la satisfacci√≥n.
- **Velocidad**: Correlaci√≥n negativa moderada. Velocidades muy altas reducen satisfacci√≥n.
- **Experiencia**: Correlaci√≥n positiva d√©bil. M√°s experiencia ligeramente aumenta satisfacci√≥n.

---

## Ventajas de Cada Algoritmo

### K-Means
‚úÖ R√°pido y escalable  
‚úÖ F√°cil de interpretar  
‚úÖ Identifica patrones naturales  
‚ùå Requiere especificar K de antemano  
‚ùå Sensible a valores at√≠picos  

### k-NN
‚úÖ Simple y efectivo  
‚úÖ No requiere entrenamiento previo  
‚úÖ Adaptable a nuevos datos  
‚ùå Lento con datasets grandes  
‚ùå Sensible a caracter√≠sticas no normalizadas  

### Feature Importance
‚úÖ Identifica factores clave  
‚úÖ Interpretaci√≥n clara  
‚úÖ Gu√≠a para mejorar sistema  
‚ùå Solo detecta relaciones lineales  
‚ùå No considera interacciones entre variables  

---

## Casos de Uso en SIAC

### 1. Segmentaci√≥n Autom√°tica (K-Means)
- **Objetivo**: Agrupar conductores con comportamientos similares
- **Aplicaci√≥n**: Personalizar alertas y recomendaciones por segmento
- **Beneficio**: Intervenci√≥n espec√≠fica para cada grupo de riesgo

### 2. Predicci√≥n de Riesgo (k-NN)
- **Objetivo**: Clasificar nuevos conductores sin historial extenso
- **Aplicaci√≥n**: Asignar nivel de riesgo a conductores nuevos
- **Beneficio**: Prevenci√≥n temprana de comportamientos riesgosos

### 3. Optimizaci√≥n de Caracter√≠sticas (Feature Importance)
- **Objetivo**: Identificar qu√© mejorar para aumentar satisfacci√≥n
- **Aplicaci√≥n**: Priorizar desarrollo de funcionalidades
- **Beneficio**: Enfoque en caracter√≠sticas que m√°s impactan satisfacci√≥n

---

## Mejoras Futuras

### 1. Redes Neuronales
- Implementar red neuronal multicapa para predicciones m√°s complejas
- Detectar patrones no lineales en los datos

### 2. Support Vector Machines (SVM)
- Clasificaci√≥n m√°s robusta con margen m√°ximo
- Manejo de espacios de alta dimensionalidad

### 3. Ensemble Methods
- Random Forest para feature importance m√°s preciso
- Gradient Boosting para mejores predicciones

### 4. Deep Learning
- LSTM para an√°lisis temporal de comportamiento
- Predicci√≥n de incidentes futuros

---

## Conclusi√≥n

Los 3 algoritmos implementados proporcionan un sistema completo de an√°lisis:

1. **K-Means**: Descubre grupos naturales en los datos
2. **k-NN**: Predice riesgo de nuevos conductores
3. **Feature Importance**: Gu√≠a decisiones de mejora

Juntos permiten tomar decisiones basadas en datos para mejorar la seguridad vial y la satisfacci√≥n de usuarios del sistema SIAC.
